{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6f0ucop5WFgB",
        "outputId": "2dbdfec6-5e66-4215-a36e-710b59ba5281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autokeras\n",
            "  Downloading autokeras-1.0.17-py3-none-any.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting keras-tuner>=1.1.0\n",
            "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (21.3)\n",
            "Collecting tensorflow>=2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.5 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.4.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.23.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (5.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.13.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n",
            "Collecting tensorboard\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.0)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.10.0.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.24.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (13.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 56.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.43.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.8.0->autokeras) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n",
            "Installing collected packages: numpy, tf-estimator-nightly, tensorboard, kt-legacy, keras, tensorflow, keras-tuner, autokeras\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed autokeras-1.0.17 keras-2.8.0 keras-tuner-1.1.0 kt-legacy-1.0.4 numpy-1.21.5 tensorboard-2.8.0 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install autokeras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d4xQayHWFgD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import autokeras as ak\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bmnd4HfWFgD"
      },
      "source": [
        "## A Simple Example\n",
        "The first step is to prepare your data. Here we use the MNIST dataset as an example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv0vEZheWFgE"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape)  # (60000, 28, 28)\n",
        "print(y_train.shape)  # (60000,)\n",
        "print(y_train[:3])  # array([7, 2, 1], dtype=uint8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3-jfJbAWFgE"
      },
      "source": [
        "The second step is to run the ImageClassifier.\n",
        "It is recommended have more trials for more complicated datasets.\n",
        "This is just a quick demo of MNIST, so we set max_trials to 1.\n",
        "For the same reason, we set epochs to 10.\n",
        "You can also leave the epochs unspecified for an adaptive number of epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnM7ctf1WFgF"
      },
      "outputs": [],
      "source": [
        "# Initialize the image classifier.\n",
        "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
        "# Feed the image classifier with training data.\n",
        "clf.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(x_test)\n",
        "print(predicted_y)\n",
        "\n",
        "\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QicWYy29WFgF"
      },
      "source": [
        "## Validation Data\n",
        "By default, AutoKeras use the last 20% of training data as validation data. As\n",
        "shown in the example below, you can use validation_split to specify the\n",
        "percentage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUy4vCTXWFgF"
      },
      "outputs": [],
      "source": [
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Split the training data and use the last 15% as validation data.\n",
        "    validation_split=0.15,\n",
        "    epochs=10,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtjiy3b6WFgG"
      },
      "source": [
        "You can also use your own validation set instead of splitting it from the\n",
        "training data with validation_data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmU87eu3WFgG"
      },
      "outputs": [],
      "source": [
        "split = 50000\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]\n",
        "x_train = x_train[:split]\n",
        "y_train = y_train[:split]\n",
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Use your own validation set.\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=10,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHSouEl7WFgH"
      },
      "source": [
        "## Customized Search Space\n",
        "For advanced users, you may customize your search space by using AutoModel\n",
        "instead of ImageClassifier. You can configure the ImageBlock for some\n",
        "high-level configurations, e.g., block_type for the type of neural network to\n",
        "search, normalize for whether to do data normalization, augment for whether to\n",
        "do data augmentation. You can also do not specify these arguments, which would\n",
        "leave the different choices to be tuned automatically. See the following\n",
        "example for detail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb_LJa4aWFgH"
      },
      "outputs": [],
      "source": [
        "input_node = ak.ImageInput()\n",
        "output_node = ak.ImageBlock(\n",
        "    # Only search ResNet architectures.\n",
        "    block_type=\"resnet\",\n",
        "    # Normalize the dataset.\n",
        "    normalize=True,\n",
        "    # Do not do data augmentation.\n",
        "    augment=False,\n",
        ")(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvMfwka_WFgH"
      },
      "source": [
        "The usage of AutoModel is similar to the functional API of Keras. Basically, you are\n",
        "building a graph, whose edges are blocks and the nodes are intermediate outputs of\n",
        "blocks. To add an edge from input_node to output_node with output_node =\n",
        "ak.[some_block]([block_args])(input_node).\n",
        "\n",
        "You can even also use more fine grained blocks to customize the search space even\n",
        "further. See the following example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UjhQMK4WFgH"
      },
      "outputs": [],
      "source": [
        "input_node = ak.ImageInput()\n",
        "output_node = ak.Normalization()(input_node)\n",
        "output_node = ak.ImageAugmentation(horizontal_flip=False)(output_node)\n",
        "output_node = ak.ResNetBlock(version=\"v2\")(output_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABoGk_-ZWFgI"
      },
      "source": [
        "## Data Format\n",
        "The AutoKeras ImageClassifier is quite flexible for the data format.\n",
        "\n",
        "For the image, it accepts data formats both with and without the channel\n",
        "dimension. The images in the MNIST dataset do not have the channel dimension.\n",
        "Each image is a matrix with shape (28, 28). AutoKeras also accepts images of\n",
        "three dimensions with the channel dimension at last, e.g., (32, 32, 3), (28,\n",
        "28, 1).\n",
        "\n",
        "For the classification labels, AutoKeras accepts both plain labels, i.e.\n",
        "strings or integers, and one-hot encoded encoded labels, i.e. vectors of 0s and\n",
        "1s.\n",
        "\n",
        "So if you prepare your data in the following way, the ImageClassifier should\n",
        "still work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7KQCGcgWFgI"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape the images to have the channel dimension.\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "# One-hot encode the labels.\n",
        "eye = np.eye(10)\n",
        "y_train = eye[y_train]\n",
        "y_test = eye[y_test]\n",
        "\n",
        "print(x_train.shape)  # (60000, 28, 28, 1)\n",
        "print(y_train.shape)  # (60000, 10)\n",
        "print(y_train[:3])\n",
        "# array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
        "#        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "#        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5H92d2bWFgI"
      },
      "source": [
        "We also support using tf.data.Dataset format for the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrQVdATWWFgI"
      },
      "outputs": [],
      "source": [
        "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,)))\n",
        "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,)))\n",
        "\n",
        "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
        "# Feed the tensorflow Dataset to the classifier.\n",
        "clf.fit(train_set, epochs=10)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(test_set)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(test_set))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Aop-j6WFgI"
      },
      "source": [
        "## Reference\n",
        "[ImageClassifier](/image_classifier),\n",
        "[AutoModel](/auto_model/#automodel-class),\n",
        "[ImageBlock](/block/#imageblock-class),\n",
        "[Normalization](/block/#normalization-class),\n",
        "[ImageAugmentation](/block/#image-augmentation-class),\n",
        "[ResNetBlock](/block/#resnetblock-class),\n",
        "[ImageInput](/node/#imageinput-class),\n",
        "[ClassificationHead](/block/#classificationhead-class).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "image_classification",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}