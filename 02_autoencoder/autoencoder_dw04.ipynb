{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import IPython.display\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.zip 파일 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# import default python-library\n",
    "########################################################################\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "########################################################################\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# import additional python-library\n",
    "########################################################################\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.core\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "import yaml\n",
    "import logging\n",
    "# from import\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# setup STD I/O\n",
    "########################################################################\n",
    "\"\"\"\n",
    "Standard output is logged in \"autoencoder.log\".\n",
    "\"\"\"\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"autoencoder.log\")\n",
    "logger = logging.getLogger(' ')\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\autoencoder\\02_autoencoder\n"
     ]
    }
   ],
   "source": [
    "# 현재 스크립트 실행 경로 출력\n",
    "print(os.getcwd())\n",
    "# c:\\workspace\\autoencoder\\02_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크립트 실행 경로 변경\n",
    "# c:\\workspace\\autoencoder\\02_autoencoder 으로 변경\n",
    "os.chdir('c:/workspace/autoencoder/02_autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\autoencoder\\02_autoencoder\n"
     ]
    }
   ],
   "source": [
    "# 현재 스크립트 실행 경로 출력\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하위에 dataset 폴더가 존재하지 않으면 생성\n",
    "os.makedirs('./dataset', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip file(.wav files) 압축 해제\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_zip = zipfile.ZipFile('./36cc_wav_files.zip')\n",
    "fantasy_zip.extractall('./dataset/')\n",
    "fantasy_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_zip = zipfile.ZipFile('./57cc_wav_files.zip')\n",
    "fantasy_zip.extractall('./dataset/')\n",
    "fantasy_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_zip = zipfile.ZipFile('./36_57_wav_files.zip')\n",
    "fantasy_zip.extractall('./dataset/')\n",
    "fantasy_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "\n",
    "# wav file Input\n",
    "def file_load(wav_name, mono=False):\n",
    "    \"\"\"\n",
    "    load .wav file.\n",
    "\n",
    "    wav_name : str\n",
    "        target .wav file\n",
    "    sampling_rate : int\n",
    "        audio file sampling_rate\n",
    "    mono : boolean\n",
    "        When load a multi channels file and this param True, the returned data will be merged for mono data\n",
    "\n",
    "    return : numpy.array( float )\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return librosa.load(wav_name, sr=None, mono=mono)\n",
    "    except:\n",
    "        logger.error(\"file_broken or not exists!! : {}\".format(wav_name))\n",
    "\n",
    "\n",
    "def demux_wav(wav_name, channel=0):\n",
    "    \"\"\"\n",
    "    demux .wav file.\n",
    "\n",
    "    wav_name : str\n",
    "        target .wav file\n",
    "    channel : int\n",
    "        target channel number\n",
    "\n",
    "    return : numpy.array( float )\n",
    "        demuxed mono data\n",
    "\n",
    "    Enabled to read multiple sampling rates.\n",
    "\n",
    "    Enabled even one channel.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        multi_channel_data, sr = file_load(wav_name)\n",
    "        if multi_channel_data.ndim <= 1:\n",
    "            return sr, multi_channel_data\n",
    "\n",
    "        return sr, np.array(multi_channel_data)[channel, :]\n",
    "\n",
    "    except ValueError as msg:\n",
    "        logger.warning(f'{msg}')\n",
    "\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# spectrograms 변환 함수 만들기\n",
    "# 참고: https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html\n",
    "def make_iamge(SOURCE,\n",
    "               TARGET,\n",
    "               n_mels=128,\n",
    "               frames=5,\n",
    "               n_fft=1024,\n",
    "               hop_length=512,\n",
    "               power=2.0):\n",
    "\n",
    "    # 01 calculate the number of dimensions\n",
    "    dims = n_mels * frames\n",
    "\n",
    "    # 02 generate melspectrogram using librosa (**kwargs == param[\"librosa\"])\n",
    "    sr, y = demux_wav(SOURCE)\n",
    "\n",
    "    # file = SOURCE\n",
    "    # y, sr = librosa.load(file) # (default  sr=22050)\n",
    "    # Return\n",
    "      # y: np.ndarray [shape=(n,) or (…, n)] / audio time series. Multi-channel is supported.\n",
    "      # sr: number > 0 [scalar / sampling rate of\n",
    "    # S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y,\n",
    "                                                     sr=sr,\n",
    "                                                     n_fft=n_fft,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     power=power)\n",
    "\n",
    "    # Returns\n",
    "      # S: np.ndarray [shape=(…, n_mels, t)] / Mel spectrogram\n",
    "    S_dB = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    if TARGET == '':\n",
    "      plt.figure(figsize=(12, 4))\n",
    "      librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "      plt.title('mel power spectrogram')\n",
    "      plt.colorbar(format='%+02.0f dB')\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "    else:\n",
    "      fig = plt.figure(figsize=(20, 20))\n",
    "      plt.axis('off')\n",
    "      librosa.display.specshow(S_dB, sr=sr)\n",
    "      plt.savefig(TARGET, bbox_inches='tight', pad_inches=0)\n",
    "      plt.close(fig)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# spectrograms 변환 함수 만들기\n",
    "# 참고: https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html\n",
    "def make_iamge2(SOURCE, TARGET, FIG_SIZE):\n",
    "\n",
    "    # 01 calculate the number of dimensions\n",
    "    #dims = n_mels * frames\n",
    "\n",
    "    # 02 generate melspectrogram using librosa (**kwargs == param[\"librosa\"])\n",
    "    sr, y = demux_wav(SOURCE)\n",
    "\n",
    "    # STFT -> spectrogram\n",
    "    hop_length = 512  # in num. of samples\n",
    "    n_fft = 2048  # window in num. of samples\n",
    "\n",
    "    # perform stft\n",
    "    stft = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "    # calculate abs values on complex numbers to get magnitude\n",
    "    spectrogram = np.abs(stft)  # np.abs(stft) ** 2\n",
    "\n",
    "    # apply logarithm to cast amplitude to Decibels\n",
    "    log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "\n",
    "    if TARGET == '':\n",
    "      plt.figure(figsize=(12, 4))\n",
    "      librosa.display.specshow(log_spectrogram, sr=sr, x_axis='time', y_axis='mel')\n",
    "      plt.title('mel power spectrogram')\n",
    "      plt.colorbar(format='%+02.0f dB')\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "    else:\n",
    "      fig = plt.figure(figsize=FIG_SIZE)\n",
    "      plt.axis('off')\n",
    "      librosa.display.specshow(log_spectrogram, sr=sr, hop_length=hop_length)\n",
    "      plt.savefig(TARGET, bbox_inches='tight', pad_inches=0)\n",
    "      plt.close(fig)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wfdb.readthedocs.io/en/latest/\n",
    "# The native Python waveform-database (WFDB) package\n",
    "# A library of tools for reading, writing, and processing WFDB signals and annotations.\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _walk at 0x000002069C0A7820>\n"
     ]
    }
   ],
   "source": [
    "# wav파일별로 Spectrogram 변환 실행위한 경로 변수 설정\n",
    "# in_path = './content/data/wav_split_final/'\n",
    "# out_path = './content/data/out/'\n",
    "in_path = './dataset/36cc_wav_files/'\n",
    "out_path = './dataset/36cc_out/'\n",
    "FIG_SIZE = (20, 20)\n",
    "# label_path = ['abnormal','normal']\n",
    "label_path = next(os.walk(in_path))[1]\n",
    "len(label_path)\n",
    "\n",
    "import os\n",
    "# walk = os.walk(\"./content/data/wav_split_final/\")\n",
    "walk = os.walk(\"./dataset/36cc_wav_files/\")\n",
    "print(walk)\n",
    "\n",
    "# Spectrogram image 변환 결과물 저장 위해 폴더 및 파일 삭제\n",
    "import shutil\n",
    "# shutil.rmtree(r'./content/data/out')\n",
    "try:\n",
    "    if os.path.exists('./dataset/36cc_out'):\n",
    "        print(\"exist\")\n",
    "        shutil.rmtree(r'./dataset/36cc_out')\n",
    "        print(\"deleted\")\n",
    "except OSError:\n",
    "    print ('Error: Creating directory. ' +  './dataset/36cc_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Spectrogram image 변환 결과물 저장폴더생성\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "# outfolder = './content/data/out'\n",
    "outfolder = './dataset/36cc_out'\n",
    "createFolder(outfolder)\n",
    "for i in label_path:\n",
    "  createFolder(outfolder+'/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_iamge(\"./19628.wav\", \"./19628.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav folders: ['abnormal', 'normal', 'normal_test']\n",
      "1 / 3  ' abnormal '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 3  ' normal '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:14<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 / 3  ' normal_test '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:08<00:00,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# wav파일별로 Spectrogram 변환 실행\n",
    "count = 0\n",
    "print(\"wav folders:\", label_path)\n",
    "for i in label_path:\n",
    "        file_list = os.listdir(in_path+i)\n",
    "        count = count + 1\n",
    "        print(count,\"/\",len(label_path),' \\'',i,'\\'')\n",
    "        for j in tqdm(file_list, position=0, leave=True):\n",
    "            SOURCE = in_path+i+\"/\"+j\n",
    "            TARGET = out_path+i+\"/\"+j[:-3]+\"jpg\"\n",
    "            make_iamge2(SOURCE, TARGET, FIG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _walk at 0x000002069C93E270>\n"
     ]
    }
   ],
   "source": [
    "# wav파일별로 Spectrogram 변환 실행위한 경로 변수 설정\n",
    "# in_path = './content/data/wav_split_final/'\n",
    "# out_path = './content/data/out/'\n",
    "in_path = './dataset/57cc_wav_files/'\n",
    "out_path = './dataset/57cc_out/'\n",
    "FIG_SIZE = (20, 20)\n",
    "# label_path = ['abnormal','normal']\n",
    "label_path = next(os.walk(in_path))[1]\n",
    "len(label_path)\n",
    "\n",
    "import os\n",
    "# walk = os.walk(\"./content/data/wav_split_final/\")\n",
    "walk = os.walk(\"./dataset/36_57_wav_files/\")\n",
    "print(walk)\n",
    "\n",
    "# Spectrogram image 변환 결과물 저장 위해 폴더 및 파일 삭제\n",
    "import shutil\n",
    "# shutil.rmtree(r'./content/data/out')\n",
    "try:\n",
    "    if os.path.exists('./dataset/57cc_out'):\n",
    "        print(\"exist\")\n",
    "        shutil.rmtree(r'./dataset/57cc_out')\n",
    "        print(\"deleted\")\n",
    "except OSError:\n",
    "    print ('Error: Creating directory. ' +  './dataset/57cc_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Spectrogram image 변환 결과물 저장폴더생성\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "# outfolder = './content/data/out'\n",
    "outfolder = './dataset/57cc_out'\n",
    "createFolder(outfolder)\n",
    "for i in label_path:\n",
    "  createFolder(outfolder+'/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav folders: ['abnormal', 'normal', 'normal_test']\n",
      "1 / 3  ' abnormal '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 3  ' normal '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:54<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 / 3  ' normal_test '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# wav파일별로 Spectrogram 변환 실행\n",
    "count = 0\n",
    "print(\"wav folders:\", label_path)\n",
    "for i in label_path:\n",
    "        file_list = os.listdir(in_path+i)\n",
    "        count = count + 1\n",
    "        print(count,\"/\",len(label_path),' \\'',i,'\\'')\n",
    "        for j in tqdm(file_list, position=0, leave=True):\n",
    "            SOURCE = in_path+i+\"/\"+j\n",
    "            TARGET = out_path+i+\"/\"+j[:-3]+\"jpg\"\n",
    "            make_iamge2(SOURCE, TARGET, FIG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _walk at 0x000002069CCC1A50>\n"
     ]
    }
   ],
   "source": [
    "# wav파일별로 Spectrogram 변환 실행위한 경로 변수 설정\n",
    "# in_path = './content/data/wav_split_final/'\n",
    "# out_path = './content/data/out/'\n",
    "in_path = './dataset/36_57_wav_files/'\n",
    "out_path = './dataset/36_57_out/'\n",
    "FIG_SIZE = (20, 20)\n",
    "# label_path = ['abnormal','normal']\n",
    "label_path = next(os.walk(in_path))[1]\n",
    "len(label_path)\n",
    "\n",
    "import os\n",
    "# walk = os.walk(\"./content/data/wav_split_final/\")\n",
    "walk = os.walk(\"./dataset/36_57_wav_files/\")\n",
    "print(walk)\n",
    "\n",
    "# Spectrogram image 변환 결과물 저장 위해 폴더 및 파일 삭제\n",
    "import shutil\n",
    "# shutil.rmtree(r'./content/data/out')\n",
    "try:\n",
    "    if os.path.exists('./dataset/36_57_out'):\n",
    "        print(\"exist\")\n",
    "        shutil.rmtree(r'./dataset/36_57_out')\n",
    "        print(\"deleted\")\n",
    "except OSError:\n",
    "    print ('Error: Creating directory. ' +  './dataset/36_57_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Spectrogram image 변환 결과물 저장폴더생성\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "# outfolder = './content/data/out'\n",
    "outfolder = './dataset/36_57_out'\n",
    "createFolder(outfolder)\n",
    "for i in label_path:\n",
    "  createFolder(outfolder+'/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# # wav파일별로 Spectrogram 변환 실행\n",
    "# count = 0\n",
    "# print(\"wav folders:\", label_path)\n",
    "# for i in label_path:\n",
    "#         file_list = os.listdir(in_path+i)\n",
    "#         count = count + 1\n",
    "#         print(count,\"/\",len(label_path),' \\'',i,'\\'')\n",
    "#         for j in tqdm(file_list, position=0, leave=True):\n",
    "#             SOURCE = in_path+i+\"/\"+j\n",
    "#             TARGET = out_path+i+\"/\"+j[:-3]+\"jpg\"\n",
    "#             make_iamge(SOURCE, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav folders: ['abnormal', 'normal', 'normal_test']\n",
      "1 / 3  ' abnormal '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 3  ' normal '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [02:31<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 / 3  ' normal_test '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# wav파일별로 Spectrogram 변환 실행\n",
    "count = 0\n",
    "print(\"wav folders:\", label_path)\n",
    "for i in label_path:\n",
    "        file_list = os.listdir(in_path+i)\n",
    "        count = count + 1\n",
    "        print(count,\"/\",len(label_path),' \\'',i,'\\'')\n",
    "        for j in tqdm(file_list, position=0, leave=True):\n",
    "            SOURCE = in_path+i+\"/\"+j\n",
    "            TARGET = out_path+i+\"/\"+j[:-3]+\"jpg\"\n",
    "            make_iamge2(SOURCE, TARGET, FIG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PIL\n",
    "# import PIL.Image\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "# 이미지 로드 및 전처리\n",
    "# 참고: https://www.tensorflow.org/tutorials/load_data/images?hl=ko\n",
    "#       Tensorflow공식 튜토리얼: 이미지 로드 및 전처리하기 \n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터세트 형식으로 만들기\n",
    "import pathlib\n",
    "\n",
    "# data_dir = pathlib.Path('./content/data/out')\n",
    "data_dir = pathlib.Path('./dataset/36cc_out')\n",
    "print(type(data_dir))\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image count\n",
    "# image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image 1개 보기\n",
    "# a_h = list(data_dir.glob('a_h/*'))\n",
    "normal = list(data_dir.glob('normal/*'))\n",
    "PIL.Image.open(str(normal[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers.core import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pathlib\n",
    "import librosa\n",
    "import librosa.display\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. Load training images  \n",
    "'''\n",
    "# resize and normalize data for training\n",
    "\n",
    "\n",
    "def create_training_data(data_path, size=224):\n",
    "    training_data = []\n",
    "    # for category in CATEGORIES:  # \"baseline\" and \"rattle\"\n",
    "\n",
    "    #     path = os.path.join(data_path, category)  # create path\n",
    "    #     # get the classification  (0 or a 1). 0=baseline 1=rattle\n",
    "    #     class_index = CATEGORIES.index(category)\n",
    "\n",
    "    # iterate over each image\n",
    "    for image in os.listdir(data_path):\n",
    "        # check file extention\n",
    "        if image.endswith(\".jpg\"):\n",
    "            try:\n",
    "                data_path = pathlib.Path(data_path)\n",
    "                full_name = str(pathlib.Path.joinpath(data_path, image))\n",
    "                data = cv2.imread(str(full_name), 0)\n",
    "                # resize to make sure data consistency\n",
    "                resized_data = cv2.resize(data, (size, size))\n",
    "                # add this to our training_data\n",
    "                training_data.append([resized_data])\n",
    "            except Exception as err:\n",
    "                print(\"an error has occured: \", err, str(full_name))\n",
    "\n",
    "    # normalize data\n",
    "    training_data = np.array(training_data)/255.\n",
    "    # reshape\n",
    "    training_data = np.array(training_data).reshape(-1, size, size)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. Build autoencoder \n",
    "'''\n",
    "# Define a convolutional Autoencoder\n",
    "\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # input layer\n",
    "        self.latent_dim = latent_dim\n",
    "        # 1st dense layer\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(latent_dim, activation='relu'),\n",
    "\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(224*224, activation='sigmoid'),\n",
    "            layers.Reshape((224, 224))\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4. Set threshold\n",
    "'''\n",
    "\n",
    "\n",
    "def model_threshold(autoencoder, x_train):\n",
    "    encoded_imgs = autoencoder.encoder(x_train).numpy()\n",
    "    decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
    "    loss = tf.keras.losses.mse(decoded_imgs, x_train)\n",
    "    threshold = np.mean(loss) + np.std(loss)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5. Make an inference\n",
    "'''\n",
    "\n",
    "\n",
    "def spectrogram_loss(autoencoder, spectrogram, size=224):\n",
    "    data = np.ndarray(shape=(1, size, size), dtype=np.float32)\n",
    "    # individual sample\n",
    "    # Load an image from a file\n",
    "    data = cv2.imread(str(spectrogram), 0)\n",
    "    # resize to make sure data consistency\n",
    "    resized_data = cv2.resize(data, (size, size))\n",
    "    # nomalize img\n",
    "    normalized_data = resized_data.astype('float32') / 255.\n",
    "    # test an image\n",
    "    encoded = autoencoder.encoder(normalized_data.reshape(-1, size, size))\n",
    "    decoded = autoencoder.decoder(encoded)\n",
    "    loss = tf.keras.losses.mse(decoded, normalized_data)\n",
    "    sample_loss = np.mean(loss) + np.std(loss)\n",
    "    return sample_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. Load training images\n",
    "'''\n",
    "data_path = \"./dataset/36cc_out/normal\"\n",
    "x_train = create_training_data(data_path)\n",
    "\n",
    "data_path = \"./dataset/36cc_out/normal_test\"\n",
    "x_test = create_training_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. Build autoencoder \n",
    "'''\n",
    "autoencoder = Autoencoder(latent_dim=64 * 4)\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "history = autoencoder.fit(x_train, x_train,\n",
    "\t\t\t\t\t\t  epochs=10,\n",
    "\t\t\t\t\t\t  shuffle=True,\n",
    "\t\t\t\t\t\t  validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a summary of architecture\n",
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load a mode\n",
    "autoencoder.save('./model/')\n",
    "autoencoder = keras.models.load_model('./model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load autoencoder model\n",
    "if autoencoder is None:\n",
    "\tautoencoder = Autoencoder(latent_dim=64 * 2)\n",
    "\tautoencoder = keras.models.load_model('./model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4. Set threshold\n",
    "'''\n",
    "threshold = model_threshold(autoencoder, x_train)\n",
    "# loss = tf.keras.losses.mse(decoded_imgs, x_train)\n",
    "# threshold = np.mean(loss) + np.std(loss)\n",
    "print(\"Loss Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load autoencoder model\n",
    "if autoencoder is None:\n",
    "\tautoencoder = keras.models.load_model('./model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5. Make an inference\n",
    "'''\n",
    "# get statistics for each spectrogram\n",
    "# file = 'c:/data/sample/test_OK_anomal_121282111NB982000301518.jpg'\n",
    "# file = 'c:/data/sample/test_OK_121282111NB982000295218.jpg'\n",
    "file = './dataset/36cc_out/abnormal/2208211119H0010019698_TDM_2022-03-30_16-22-03__Microphone.jpg'\n",
    "sample = plt.imread(file)\n",
    "plt.imshow(sample)\n",
    "sample = pathlib.Path(file)\n",
    "sample_loss = spectrogram_loss(autoencoder, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_loss > threshold:\n",
    "\tprint(\n",
    "\t\tf'Loss is bigger than threshold \\n \\\n",
    "\t\t  Sample Loss: {sample_loss} \\n \\\n",
    "\t\t  Threshold: {threshold} ')\n",
    "else:\n",
    "\tprint(\n",
    "\t\tf'Loss is smaller than threshold \\n \\\n",
    "\t\t  Sample Loss: {sample_loss} \\n \\\n",
    "\t\t  Threshold: {threshold} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5. Make an inference\n",
    "'''\n",
    "# get statistics for each spectrogram\n",
    "# file = 'c:/data/sample/test_OK_anomal_121282111NB982000301518.jpg'\n",
    "# file = 'c:/data/sample/test_OK_121282111NB982000295218.jpg'\n",
    "file = './dataset/36cc_out/abnormal/2208212119H0010019788_TDM_2022-03-30_15-55-34__Microphone.jpg'\n",
    "sample = plt.imread(file)\n",
    "plt.imshow(sample)\n",
    "sample = pathlib.Path(file)\n",
    "sample_loss = spectrogram_loss(autoencoder, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_loss > threshold:\n",
    "\tprint(\n",
    "\t\tf'Loss is bigger than threshold \\n \\\n",
    "\t\t  Sample Loss: {sample_loss} \\n \\\n",
    "\t\t  Threshold: {threshold} ')\n",
    "else:\n",
    "\tprint(\n",
    "\t\tf'Loss is smaller than threshold \\n \\\n",
    "\t\t  Sample Loss: {sample_loss} \\n \\\n",
    "\t\t  Threshold: {threshold} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "K-fold validation\n",
    "'''\n",
    "k = 4\n",
    "num_val_samples = len(X) // k\n",
    "\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"Processing fold #{i}\")\n",
    "    val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    # i = 0 ==> val_data = X[0:9], val_targets = y[0:9]        \n",
    "    # i = 1 ==> val_data = X[9:18], val_targets = y[9:18]     \n",
    "    # i = 2 ==> val_data = X[18:27], val_targets = y[18:27]     \n",
    "    # i = 3 ==> val_data = X[27:36], val_targets = y[27:36]\n",
    "    partial_train_data = np.concatenate(\n",
    "        [X[:i * num_val_samples],\n",
    "            X[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [y[:i * num_val_samples],\n",
    "            y[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    # i = 0 ==> partial_training_data = [X[:0],X[9:]], partial_train_targets = [y[:0],y[9:]]\n",
    "    # i = 1 ==> partial_training_data = [X[:9],X[18:]], partial_train_targets = [y[:9],y[18:]]\n",
    "    # i = 2 ==> partial_training_data = [X[:18],X[27:]], partial_train_targets = [y[:18],y[27:]]\n",
    "    # i = 3 ==> partial_training_data = [X[:27],X[36:]], partial_train_targets = [y[:27],y[36:]]\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "                epochs=num_epochs,\n",
    "                batch_size=16, verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(\n",
    "        val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ae2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d53f8d3696fa07b63b30438e5eb8438fa75e4f2f54aedbe0dcd668d7dbe88084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
