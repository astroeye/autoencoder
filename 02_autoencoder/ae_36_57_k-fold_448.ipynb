{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# import default python-library\n",
    "########################################################################\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "########################################################################\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# import additional python-library\n",
    "########################################################################\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.core\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "import yaml\n",
    "import logging\n",
    "# from import\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\autoencoder\\02_autoencoder\n"
     ]
    }
   ],
   "source": [
    "# 현재 스크립트 실행 경로 출력\n",
    "print(os.getcwd())\n",
    "# c:\\workspace\\autoencoder\\02_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크립트 실행 경로 변경\n",
    "# c:\\workspace\\autoencoder\\02_autoencoder 으로 변경\n",
    "os.chdir('c:/workspace/autoencoder/02_autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\autoencoder\\02_autoencoder\n"
     ]
    }
   ],
   "source": [
    "# 현재 스크립트 실행 경로 출력\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "\n",
    "# wav file Input\n",
    "def file_load(wav_name, mono=False):\n",
    "    \"\"\"\n",
    "    load .wav file.\n",
    "\n",
    "    wav_name : str\n",
    "        target .wav file\n",
    "    sampling_rate : int\n",
    "        audio file sampling_rate\n",
    "    mono : boolean\n",
    "        When load a multi channels file and this param True, the returned data will be merged for mono data\n",
    "\n",
    "    return : numpy.array( float )\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return librosa.load(wav_name, sr=None, mono=mono)\n",
    "    except:\n",
    "        logger.error(\"file_broken or not exists!! : {}\".format(wav_name))\n",
    "\n",
    "\n",
    "def demux_wav(wav_name, channel=0):\n",
    "    \"\"\"\n",
    "    demux .wav file.\n",
    "\n",
    "    wav_name : str\n",
    "        target .wav file\n",
    "    channel : int\n",
    "        target channel number\n",
    "\n",
    "    return : numpy.array( float )\n",
    "        demuxed mono data\n",
    "\n",
    "    Enabled to read multiple sampling rates.\n",
    "\n",
    "    Enabled even one channel.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        multi_channel_data, sr = file_load(wav_name)\n",
    "        if multi_channel_data.ndim <= 1:\n",
    "            return sr, multi_channel_data\n",
    "\n",
    "        return sr, np.array(multi_channel_data)[channel, :]\n",
    "\n",
    "    except ValueError as msg:\n",
    "        logger.warning(f'{msg}')\n",
    "\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# spectrograms 변환 함수 만들기\n",
    "# 참고: https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html\n",
    "def make_iamge(SOURCE,\n",
    "               TARGET,\n",
    "               n_mels=128,\n",
    "               frames=5,\n",
    "               n_fft=1024,\n",
    "               hop_length=512,\n",
    "               power=2.0):\n",
    "\n",
    "    # 01 calculate the number of dimensions\n",
    "    dims = n_mels * frames\n",
    "\n",
    "    # 02 generate melspectrogram using librosa (**kwargs == param[\"librosa\"])\n",
    "    sr, y = demux_wav(SOURCE)\n",
    "\n",
    "    # file = SOURCE\n",
    "    # y, sr = librosa.load(file) # (default  sr=22050)\n",
    "    # Return\n",
    "      # y: np.ndarray [shape=(n,) or (…, n)] / audio time series. Multi-channel is supported.\n",
    "      # sr: number > 0 [scalar / sampling rate of\n",
    "    # S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y,\n",
    "                                                     sr=sr,\n",
    "                                                     n_fft=n_fft,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     power=power)\n",
    "\n",
    "    # Returns\n",
    "      # S: np.ndarray [shape=(…, n_mels, t)] / Mel spectrogram\n",
    "    S_dB = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    if TARGET == '':\n",
    "      plt.figure(figsize=(12, 4))\n",
    "      librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "      plt.title('mel power spectrogram')\n",
    "      plt.colorbar(format='%+02.0f dB')\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "    else:\n",
    "      fig = plt.figure(figsize=(15, 15))\n",
    "      plt.axis('off')\n",
    "      librosa.display.specshow(S_dB, sr=sr)\n",
    "      plt.savefig(TARGET, bbox_inches='tight', pad_inches=0)\n",
    "      plt.close(fig)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# spectrograms 변환 함수 만들기\n",
    "# 참고: https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html\n",
    "def make_iamge2(SOURCE, TARGET, FIG_SIZE):\n",
    "\n",
    "    # 01 calculate the number of dimensions\n",
    "    #dims = n_mels * frames\n",
    "\n",
    "    # 02 generate melspectrogram using librosa (**kwargs == param[\"librosa\"])\n",
    "    sr, y = demux_wav(SOURCE)\n",
    "\n",
    "    # STFT -> spectrogram\n",
    "    hop_length = 512  # in num. of samples\n",
    "    n_fft = 2048  # window in num. of samples\n",
    "\n",
    "    # perform stft\n",
    "    stft = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "    # calculate abs values on complex numbers to get magnitude\n",
    "    spectrogram = np.abs(stft)  # np.abs(stft) ** 2\n",
    "\n",
    "    # apply logarithm to cast amplitude to Decibels\n",
    "    log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "\n",
    "    if TARGET == '':\n",
    "      plt.figure(figsize=(12, 4))\n",
    "      librosa.display.specshow(log_spectrogram, sr=sr, x_axis='time', y_axis='mel')\n",
    "      plt.title('mel power spectrogram')\n",
    "      plt.colorbar(format='%+02.0f dB')\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "    else:\n",
    "      fig = plt.figure(figsize=FIG_SIZE)\n",
    "      plt.axis('off')\n",
    "      librosa.display.specshow(log_spectrogram, sr=sr, hop_length=hop_length)\n",
    "      plt.savefig(TARGET, bbox_inches='tight', pad_inches=0)\n",
    "      plt.close(fig)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wfdb.readthedocs.io/en/latest/\n",
    "# The native Python waveform-database (WFDB) package\n",
    "# A library of tools for reading, writing, and processing WFDB signals and annotations.\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PIL\n",
    "# import PIL.Image\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "# 이미지 로드 및 전처리\n",
    "# 참고: https://www.tensorflow.org/tutorials/load_data/images?hl=ko\n",
    "#       Tensorflow공식 튜토리얼: 이미지 로드 및 전처리하기 \n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pathlib.WindowsPath'>\n",
      "dataset\\36_57_out\n"
     ]
    }
   ],
   "source": [
    "# 데이터세트 형식으로 만들기\n",
    "import pathlib\n",
    "\n",
    "# data_dir = pathlib.Path('./content/data/out')\n",
    "data_dir = pathlib.Path('./dataset/36_57_out')\n",
    "print(type(data_dir))\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "# image count\n",
    "# image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers.core import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pathlib\n",
    "import librosa\n",
    "import librosa.display\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. Load training images  \n",
    "'''\n",
    "# resize and normalize data for training\n",
    "\n",
    "\n",
    "def create_training_data(data_path, size=224*2):\n",
    "    training_data = []\n",
    "    # for category in CATEGORIES:  # \"baseline\" and \"rattle\"\n",
    "\n",
    "    #     path = os.path.join(data_path, category)  # create path\n",
    "    #     # get the classification  (0 or a 1). 0=baseline 1=rattle\n",
    "    #     class_index = CATEGORIES.index(category)\n",
    "\n",
    "    # iterate over each image\n",
    "    for image in os.listdir(data_path):\n",
    "        # check file extention\n",
    "        if image.endswith(\".jpg\"):\n",
    "            try:\n",
    "                data_path = pathlib.Path(data_path)\n",
    "                full_name = str(pathlib.Path.joinpath(data_path, image))\n",
    "                data = cv2.imread(str(full_name), 0)\n",
    "                # resize to make sure data consistency\n",
    "                resized_data = cv2.resize(data, (size, size))\n",
    "                # add this to our training_data\n",
    "                training_data.append([resized_data])\n",
    "            except Exception as err:\n",
    "                print(\"an error has occured: \", err, str(full_name))\n",
    "\n",
    "    # normalize data\n",
    "    training_data = np.array(training_data)/255.\n",
    "    # reshape\n",
    "    training_data = np.array(training_data).reshape(-1, size, size)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. Build autoencoder \n",
    "'''\n",
    "# Define a convolutional Autoencoder\n",
    "\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # input layer\n",
    "        self.latent_dim = latent_dim\n",
    "        # 1st dense layer\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            #layers.Dense(latent_dim, activation='relu'),\n",
    "            layers.Dense(latent_dim, activation='sigmoid'),\n",
    "\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(224*2*224*2, activation='sigmoid'),\n",
    "            layers.Reshape((224*2, 224*2))\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4. Set threshold\n",
    "'''\n",
    "\n",
    "\n",
    "def model_threshold(autoencoder, x_train):\n",
    "    encoded_imgs = autoencoder.encoder(x_train).numpy()\n",
    "    decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
    "    loss = tf.keras.losses.mse(decoded_imgs, x_train)\n",
    "    threshold = np.mean(loss) + np.std(loss)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5. Make an inference\n",
    "'''\n",
    "\n",
    "\n",
    "def spectrogram_loss(autoencoder, spectrogram, size=224*2):\n",
    "    data = np.ndarray(shape=(1, size, size), dtype=np.float32)\n",
    "    # individual sample\n",
    "    # Load an image from a file\n",
    "    data = cv2.imread(str(spectrogram), 0)\n",
    "    # resize to make sure data consistency\n",
    "    resized_data = cv2.resize(data, (size, size))\n",
    "    # nomalize img\n",
    "    normalized_data = resized_data.astype('float32') / 255.\n",
    "    # test an image\n",
    "    encoded = autoencoder.encoder(normalized_data.reshape(-1, size, size))\n",
    "    decoded = autoencoder.decoder(encoded)\n",
    "    loss = tf.keras.losses.mse(decoded, normalized_data)\n",
    "    sample_loss = np.mean(loss) + np.std(loss)\n",
    "    return sample_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. Load training images\n",
    "'''\n",
    "data_path = \"./dataset/36_57_out/normal\"\n",
    "x_train = create_training_data(data_path)\n",
    "\n",
    "data_path = \"./dataset/36_57_out/normal_test\"\n",
    "x_test = create_training_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# K-fold validation\n",
    "# '''\n",
    "# X = x_train\n",
    "# y = x_train\n",
    "\n",
    "# k = 4\n",
    "# num_val_samples = len(X) // k\n",
    "\n",
    "# num_epochs = 100\n",
    "# all_scores = []\n",
    "\n",
    "# for i in range(k):\n",
    "#     print(f\"Processing fold #{i}\")\n",
    "#     val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "#     val_targets = y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "#     # i = 0 ==> val_data = X[0:9], val_targets = y[0:9]        \n",
    "#     # i = 1 ==> val_data = X[9:18], val_targets = y[9:18]     \n",
    "#     # i = 2 ==> val_data = X[18:27], val_targets = y[18:27]     \n",
    "#     # i = 3 ==> val_data = X[27:36], val_targets = y[27:36]\n",
    "#     partial_train_data = np.concatenate(\n",
    "#         [X[:i * num_val_samples],\n",
    "#             X[(i + 1) * num_val_samples:]],\n",
    "#         axis=0)\n",
    "#     partial_train_targets = np.concatenate(\n",
    "#         [y[:i * num_val_samples],\n",
    "#             y[(i + 1) * num_val_samples:]],\n",
    "#         axis=0)\n",
    "#     # i = 0 ==> partial_training_data = [X[:0],X[9:]], partial_train_targets = [y[:0],y[9:]]\n",
    "#     # i = 1 ==> partial_training_data = [X[:9],X[18:]], partial_train_targets = [y[:9],y[18:]]\n",
    "#     # i = 2 ==> partial_training_data = [X[:18],X[27:]], partial_train_targets = [y[:18],y[27:]]\n",
    "#     # i = 3 ==> partial_training_data = [X[:27],X[36:]], partial_train_targets = [y[:27],y[36:]]\n",
    "#     autoencoder = Autoencoder(latent_dim=64 * 4)\n",
    "#     autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError(), metrics=[\"mae\"])\n",
    "#     hist = autoencoder.fit(partial_train_data, partial_train_targets,\n",
    "#                             validation_data=(val_data, val_targets),\n",
    "#                             epochs=num_epochs, batch_size=16, verbose=0)\n",
    "#     val_mse, val_mae = autoencoder.evaluate(\n",
    "#         val_data, val_targets, verbose=0)\n",
    "#     all_scores.append(val_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate all_scores\n",
    "# all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold #0\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 212ms/step - loss: 0.1159 - val_loss: 0.1395\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.1031 - val_loss: 0.1181\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0840 - val_loss: 0.0944\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0643 - val_loss: 0.0723\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0471 - val_loss: 0.0537\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0332 - val_loss: 0.0395\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0234 - val_loss: 0.0292\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0171 - val_loss: 0.0220\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0130 - val_loss: 0.0171\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0108 - val_loss: 0.0139\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0096 - val_loss: 0.0118\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0084 - val_loss: 0.0091\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0082 - val_loss: 0.0088\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0080 - val_loss: 0.0089\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0079 - val_loss: 0.0091\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0077 - val_loss: 0.0094\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0075 - val_loss: 0.0097\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0072 - val_loss: 0.0106\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0071 - val_loss: 0.0110\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0070 - val_loss: 0.0114\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0069 - val_loss: 0.0118\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0068 - val_loss: 0.0121\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0068 - val_loss: 0.0123\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0068 - val_loss: 0.0125\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0067 - val_loss: 0.0125\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0067 - val_loss: 0.0126\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0067 - val_loss: 0.0125\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0067 - val_loss: 0.0125\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0066 - val_loss: 0.0124\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0066 - val_loss: 0.0123\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0066 - val_loss: 0.0122\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0066 - val_loss: 0.0121\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0066 - val_loss: 0.0120\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0066 - val_loss: 0.0119\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0066 - val_loss: 0.0119\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0065 - val_loss: 0.0121\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0065 - val_loss: 0.0122\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0065 - val_loss: 0.0121\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0065 - val_loss: 0.0121\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0065 - val_loss: 0.0121\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0064 - val_loss: 0.0120\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0064 - val_loss: 0.0120\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0064 - val_loss: 0.0120\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0064 - val_loss: 0.0120\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0064 - val_loss: 0.0118\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0064 - val_loss: 0.0118\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0064 - val_loss: 0.0118\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0064 - val_loss: 0.0120\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0064 - val_loss: 0.0120\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "loss average:  0.011178847239352762\n",
      "val_loss average:  0.016491357376798986\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold #1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ResourceExhaustedError: Exception encountered when calling layer \"autoencoder_1\" (type Autoencoder).\n    \n    in user code:\n    \n        File \"C:\\Users\\astro1\\AppData\\Local\\Temp\\ipykernel_6744\\515145012.py\", line 25, in call  *\n            encoded = self.encoder(x)\n        File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\backend.py\", line 1920, in random_uniform\n            return tf.random.uniform(\n    \n        ResourceExhaustedError: Exception encountered when calling layer \"sequential_2\" (type Sequential).\n        \n        failed to allocate memory [Op:AddV2]\n        \n        Call arguments received:\n          • inputs=tf.Tensor(shape=(None, 448, 448), dtype=float32)\n          • training=True\n          • mask=None\n    \n    \n    Call arguments received:\n      • x=tf.Tensor(shape=(None, 448, 448), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\workspace\\autoencoder\\02_autoencoder\\ae_36_57_k-fold_448.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=27'>28</a>\u001b[0m     autoencoder \u001b[39m=\u001b[39m Autoencoder(latent_dim\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=28'>29</a>\u001b[0m     autoencoder\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39mlosses\u001b[39m.\u001b[39mMeanSquaredError())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=29'>30</a>\u001b[0m     history \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mfit(partial_train_data, partial_train_targets,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=30'>31</a>\u001b[0m \t\t\t\t\t\t\u001b[39m#shuffle=True,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=31'>32</a>\u001b[0m                         validation_data\u001b[39m=\u001b[39;49m(val_data, val_targets),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=32'>33</a>\u001b[0m                         epochs\u001b[39m=\u001b[39;49mnum_epochs)\u001b[39m#, batch_size=16, verbose=0)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=33'>34</a>\u001b[0m     \u001b[39m#mae_history = history.history[\"val_mae\"]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=34'>35</a>\u001b[0m     \u001b[39m#all_mae_histories.append(mae_history)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=35'>36</a>\u001b[0m     \u001b[39m# Fold별 그래프 표시하기 위해 추가함\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=39'>40</a>\u001b[0m     \u001b[39m# #plt.ylim([0, 0.30])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=40'>41</a>\u001b[0m     \u001b[39m# plt.show()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/autoencoder/02_autoencoder/ae_36_57_k-fold_448.ipynb#ch0000021?line=42'>43</a>\u001b[0m     mse_history \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/astro1/anaconda3/envs/ae/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/astro1/anaconda3/envs/ae/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/astro1/anaconda3/envs/ae/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/astro1/anaconda3/envs/ae/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/astro1/anaconda3/envs/ae/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/astro1/anaconda3/envs/ae/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/astro1/anaconda3/envs/ae/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/astro1/anaconda3/envs/ae/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///c%3A/Users/astro1/anaconda3/envs/ae/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/astro1/anaconda3/envs/ae/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: in user code:\n\n    File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ResourceExhaustedError: Exception encountered when calling layer \"autoencoder_1\" (type Autoencoder).\n    \n    in user code:\n    \n        File \"C:\\Users\\astro1\\AppData\\Local\\Temp\\ipykernel_6744\\515145012.py\", line 25, in call  *\n            encoded = self.encoder(x)\n        File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"c:\\Users\\astro1\\anaconda3\\envs\\ae\\lib\\site-packages\\keras\\backend.py\", line 1920, in random_uniform\n            return tf.random.uniform(\n    \n        ResourceExhaustedError: Exception encountered when calling layer \"sequential_2\" (type Sequential).\n        \n        failed to allocate memory [Op:AddV2]\n        \n        Call arguments received:\n          • inputs=tf.Tensor(shape=(None, 448, 448), dtype=float32)\n          • training=True\n          • mask=None\n    \n    \n    Call arguments received:\n      • x=tf.Tensor(shape=(None, 448, 448), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "K-fold validation\n",
    "'''\n",
    "X = x_train\n",
    "y = x_train\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(X) // k\n",
    "\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "all_mse_histories = []\n",
    "all_val_mse_histories = []\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print(f\"Processing fold #{i}\")\n",
    "    val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate(\n",
    "        [X[:i * num_val_samples],\n",
    "            X[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [y[:i * num_val_samples],\n",
    "            y[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    autoencoder = Autoencoder(latent_dim=64 * 4)\n",
    "    autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "    history = autoencoder.fit(partial_train_data, partial_train_targets,\n",
    "\t\t\t\t\t\t#shuffle=True,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs)#, batch_size=16, verbose=0)\n",
    "    #mae_history = history.history[\"val_mae\"]\n",
    "    #all_mae_histories.append(mae_history)\n",
    "    # Fold별 그래프 표시하기 위해 추가함\n",
    "    # plt.plot(range(1, len(mae_history) + 1), mae_history)\n",
    "    # plt.xlabel(\"Epochs\")\n",
    "    # plt.ylabel(\"Validation MAE\")\n",
    "    # #plt.ylim([0, 0.30])\n",
    "    # plt.show()\n",
    "\n",
    "    mse_history = history.history[\"loss\"]\n",
    "    all_mse_histories.append(mse_history)\n",
    "    print(\"loss average: \", np.mean(mse_history))\n",
    "    \n",
    "    val_mse_history = history.history[\"val_loss\"]\n",
    "    all_val_mse_histories.append(val_mse_history)\n",
    "    print(\"val_loss average: \", np.mean(val_mse_history))\n",
    "\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 0.150])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all loss average:  0.00540985530387843\n",
      "all val loss average:  0.007029608078883029\n"
     ]
    }
   ],
   "source": [
    "print(\"all loss average: \", np.mean(all_mse_histories))\n",
    "print(\"all val loss average: \", np.mean(all_val_mse_histories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the history of successive mean K-fold validation scores\n",
    "average_mse_history = [\n",
    "    np.mean([x[i] for x in all_mse_histories]) for i in range(num_epochs)]\n",
    "average_val_mse_history = [\n",
    "    np.mean([x[i] for x in all_val_mse_histories]) for i in range(num_epochs)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting validation scores\n",
    "plt.plot(range(1, len(average_mse_history) + 1), average_mse_history, label=\"Training Loss\")\n",
    "plt.plot(range(1, len(average_val_mse_history) + 1), average_val_mse_history, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.ylim([0, 0.15])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d53f8d3696fa07b63b30438e5eb8438fa75e4f2f54aedbe0dcd668d7dbe88084"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ae2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
