{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://51.195.220.149/book.php?id=964\n",
    "# https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/blob/master/chapter3-autoencoders/autoencoder-2dim-mnist-3.2.2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Example of autoencoder model on MNIST dataset using 2dim latent\n",
    "The autoencoder forces the encoder to discover 2-dim latent vector\n",
    "that the decoder can recover the original input. The 2-dim latent\n",
    "vector is projected on 2D space to analyze the distribution of code\n",
    "in the latent space. The latent space can be navigated by varying the\n",
    "values of latent vector to produce new MNIST digits.\n",
    "This autoencoder has modular design. The encoder, decoder and autoencoder\n",
    "are 3 models that share weights. For example, after training the\n",
    "autoencoder, the encoder can be used to  generate latent vectors\n",
    "of input data for low-dim visualization like PCA or TSNE.\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=32,\n",
    "                 model_name=\"autoencoder_2dim\"):\n",
    "    \"\"\"Plots 2-dim latent values as scatter plot of digits\n",
    "        then, plot MNIST digits as function of 2-dim latent vector\n",
    "    Arguments:\n",
    "        models (list): encoder and decoder models\n",
    "        data (list): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    xmin = ymin = -4\n",
    "    xmax = ymax = +4\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"latent_2dim.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z = encoder.predict(x_test,\n",
    "                        batch_size=batch_size)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # axes x and y ranges\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([xmin,xmax])\n",
    "    axes.set_ylim([ymin,ymax])\n",
    "\n",
    "    # subsample to reduce density of points on the plot\n",
    "    z = z[0::2]\n",
    "    y_test = y_test[0::2]\n",
    "    plt.scatter(z[:, 0], z[:, 1], marker=\"\")\n",
    "    for i, digit in enumerate(y_test):\n",
    "        axes.annotate(digit, (z[i, 0], z[i, 1]))\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "    # display a 30x30 2D manifold of the digits\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(xmin, xmax, n)\n",
    "    grid_y = np.linspace(ymin, ymax, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to (28, 28, 1) and normalize input images\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 32\n",
    "kernel_size = 3\n",
    "latent_dim = 2\n",
    "# encoder/decoder number of CNN layers and filters per layer\n",
    "layer_filters = [32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the autoencoder model\n",
    "# first build the encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "# stack of Conv2D(32)-Conv2D(64)\n",
    "for filters in layer_filters:\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               activation='relu',\n",
    "               strides=2,\n",
    "               padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape info needed to build decoder model so we don't do hand computation\n",
    "# the input to the decoder's first Conv2DTranspose will have this shape\n",
    "# shape is (7, 7, 64) which is processed by the decoder back to (28, 28, 1)\n",
    "shape = K.int_shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate latent vector\n",
    "x = Flatten()(x)\n",
    "latent = Dense(latent_dim, name='latent_vector')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " latent_vector (Dense)       (None, 2)                 6274      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,090\n",
      "Trainable params: 25,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# instantiate encoder model\n",
    "encoder = Model(inputs, latent, name='encoder')\n",
    "encoder.summary()\n",
    "plot_model(encoder, to_file='encoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "# use the shape (7, 7, 64) that was earlier saved\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
    "# from vector to suitable shape for transposed conv\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack of Conv2DTranspose(64)-Conv2DTranspose(32)\n",
    "for filters in layer_filters[::-1]:\n",
    "    x = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='relu',\n",
    "                        strides=2,\n",
    "                        padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the input\n",
    "outputs = Conv2DTranspose(filters=1,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='sigmoid',\n",
    "                          padding='same',\n",
    "                          name='decoder_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3136)              9408      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " decoder_output (Conv2DTrans  (None, 28, 28, 1)        289       \n",
      " pose)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,089\n",
      "Trainable params: 65,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "plot_model(decoder, to_file='decoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 2)                 25090     \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 28, 28, 1)         65089     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,179\n",
      "Trainable params: 90,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# autoencoder = encoder + decoder\n",
    "# instantiate autoencoder model\n",
    "autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "autoencoder.summary()\n",
    "plot_model(autoencoder, to_file='autoencoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error (MSE) loss function, Adam optimizer\n",
    "autoencoder.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 8s 3ms/step - loss: 0.0544 - val_loss: 0.0478\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0464 - val_loss: 0.0453\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0445 - val_loss: 0.0444\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0436 - val_loss: 0.0436\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0429 - val_loss: 0.0433\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0425 - val_loss: 0.0428\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0421 - val_loss: 0.0423\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0419 - val_loss: 0.0426\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0416 - val_loss: 0.0421\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0414 - val_loss: 0.0421\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0413 - val_loss: 0.0417\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0412 - val_loss: 0.0417\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0410 - val_loss: 0.0415\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0409 - val_loss: 0.0415\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0408 - val_loss: 0.0413\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0407 - val_loss: 0.0413\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0406 - val_loss: 0.0415\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0405 - val_loss: 0.0414\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0404 - val_loss: 0.0412\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0404 - val_loss: 0.0412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26498d79850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the autoencoder\n",
    "autoencoder.fit(x_train,\n",
    "                x_train,\n",
    "                validation_data=(x_test, x_test),\n",
    "                epochs=20,\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the autoencoder output from test data\n",
    "x_decoded = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the 1st 8 test input and decoded images\n",
    "imgs = np.concatenate([x_test[:8], x_decoded[:8]])\n",
    "imgs = imgs.reshape((4, 4, image_size, image_size))\n",
    "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.title('Input: 1st 2 rows, Decoded: last 2 rows')\n",
    "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
    "plt.savefig('input_and_decoded.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project the 2-dim latent on 2D space\n",
    "models = (encoder, decoder)\n",
    "data = (x_test, y_test)\n",
    "plot_results(models, data,\n",
    "             batch_size=batch_size,\n",
    "             model_name=\"autoencoder-2dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cda25b447d24e0c552e167f4581e6082f9a8d9051bb076b8c83c8431f397ae1f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
